import tflite_runtime.interpreter as tflite
import numpy as np
import cv2
import time
import matplotlib.pyplot as plt
import os

# source /home/willtek/work/env/bin/activate

# ignore subnormal warnings
import warnings
warnings.simplefilter("ignore", UserWarning)

# use_small_model = True
# model_path = "/home/willtek/Documents/mini_project/weights/sample.tflite"

use_small_model = False  # True: (1, 64, 64, 3), False: (1, 3, 300, 400)
model_path = "/home/willtek/Documents/mini_project/weights/best_epoch.tflite"
# model_path = "/home/willtek/Documents/mini_project/weights/final.tflite"

# GPU Delegate ì„¤ì • (ë¼ì¦ˆë² ë¦¬íŒŒì´ì—ì„œ GPU ì‚¬ìš©)
try:
    interpreter = tflite.Interpreter(
        model_path=model_path,
        experimental_delegates=[tflite.load_delegate('libtensorflowlite_delegate_gpu.so')]
    )
    print("âœ… GPU ê°€ì† í™œì„±í™”ë¨")
except:
    interpreter = tflite.Interpreter(model_path=model_path, num_threads=4)
    # interpreter = tflite.Interpreter(model_path=model_path)
    print("ğŸ–¥ï¸ CPUë¡œ ì‹¤í–‰")

interpreter.allocate_tensors()

# ëª¨ë¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
input_dtype = input_details[0]['dtype']
input_shape = input_details[0]['shape']

# ëª¨ë¸ ì…ë ¥ í¬ê¸° ì„¤ì •
if use_small_model:
    batch_size, height, width, channels = input_shape  # (1, 64, 64, 3)
else:
    batch_size, channels, height, width = input_shape  # (1, 3, 300, 400)

print(f"ğŸ“ Model Input Shape: {input_shape}")

# í´ë˜ìŠ¤ ë§¤í•‘
ansToText = {0: 'rock', 1: 'scissors', 2: 'paper'}
colorList = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]

# ì €ì¥í•  ë””ë ‰í† ë¦¬ ìƒì„±
output_dir = "frames_output"
os.makedirs(output_dir, exist_ok=True)

# ì¹´ë©”ë¼ ì„¤ì •
cap = cv2.VideoCapture(0)  # ì›¹ìº  ì‚¬ìš©
cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)

# ì €ì¥í•  í”„ë ˆì„ ê°œìˆ˜
frame_count = 5
saved_frames = 0

def preprocess_frame(frame):
    """ì¹´ë©”ë¼ í”„ë ˆì„ì„ ëª¨ë¸ ì…ë ¥ í¬ê¸°ì— ë§ê²Œ ë³€í™˜"""
    frame = cv2.resize(frame, (width, height))  # ëª¨ë¸ ì…ë ¥ í¬ê¸°ë¡œ ì¡°ì •
    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # BGR -> RGB ë³€í™˜
    frame = frame.astype(np.float32) / 255.0  # ì •ê·œí™”
    
    if use_small_model:
        frame = np.expand_dims(frame, axis=0)  # (1, 64, 64, 3)
    else:
        frame = np.transpose(frame, (2, 0, 1))  # (H, W, C) â†’ (C, H, W)
        frame = np.expand_dims(frame, axis=0)  # (1, C, H, W)
    
    return frame

def softmax(logits):
    """Softmax í•¨ìˆ˜ ì ìš©"""
    exp_logits = np.exp(logits - np.max(logits))  # ì˜¤ë²„í”Œë¡œìš° ë°©ì§€
    return exp_logits / np.sum(exp_logits)

while cap.isOpened() and saved_frames < frame_count:
    ret, frame = cap.read()
    if not ret:
        break

    frame = cv2.flip(frame, 1)  # ì¢Œìš° ë°˜ì „ (ì›¹ìº  ìì—°ìŠ¤ëŸ¬ìš´ ë°©í–¥)

    # ì „ì²´ í”„ë ˆì„ ì²˜ë¦¬ ì‹œì‘ ì‹œê°„
    start_time = time.time()

    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    input_data = preprocess_frame(frame)

    # ëª¨ë¸ ì…ë ¥ ì„¤ì •
    interpreter.set_tensor(input_details[0]['index'], input_data.astype(input_dtype))

    # ëª¨ë¸ ì¶”ë¡  ì‹œì‘ ì‹œê°„
    inference_start = time.time()
    interpreter.invoke()
    inference_end = time.time()

    # ì¶”ë¡  Latency ê³„ì‚° (ms)
    inference_time = (inference_end - inference_start) * 1000  # ms ë‹¨ìœ„

    # ê²°ê³¼ ê°€ì ¸ì˜¤ê¸° (logits)
    logits = interpreter.get_tensor(output_details[0]['index'])[0]

    # Softmax ì ìš©
    softmax_probs = softmax(logits)

    # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ë˜ìŠ¤ ì„ íƒ
    ans = np.argmax(softmax_probs)
    confidence = softmax_probs[ans]  # í™•ë¥ ê°’

    # 50% ë¯¸ë§Œ í™•ë¥ ì´ë©´ Invalid ì²˜ë¦¬
    if confidence < 0.5:
        text = "Invalid"
        text_color = (255, 255, 255)  # í°ìƒ‰
    else:
        text = f"{ansToText[ans]} ({confidence * 100:.1f}%)"
        text_color = colorList[ans]

    # ì „ì²´ í”„ë ˆì„ ì²˜ë¦¬ ì¢…ë£Œ ì‹œê°„
    end_time = time.time()
    total_time = end_time - start_time

    # FPS ê³„ì‚°
    fps = 1 / total_time

    # ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ
    plt.figure(figsize=(6, 4))
    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    plt.title(f"Prediction: {text} | FPS: {fps:.1f} | Latency: {inference_time:.2f}ms")
    plt.axis("off")

    # í”„ë ˆì„ ì €ì¥
    save_path = os.path.join(output_dir, f"frame_{saved_frames + 1}.png")
    plt.savefig(save_path, bbox_inches="tight")
    plt.close()

    print(f"âœ… Saved: {save_path} | FPS: {fps:.1f} | Latency: {inference_time:.2f}ms | Confidence: {confidence:.2f}")
    print(f"Softmax: {softmax_probs}")  # Softmax í™•ë¥  ì¶œë ¥

    saved_frames += 1

cap.release()
print("ğŸ‰ ëª¨ë“  í”„ë ˆì„ ì €ì¥ ì™„ë£Œ!")
